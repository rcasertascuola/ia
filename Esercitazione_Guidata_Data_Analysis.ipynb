{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione Guidata: Analisi di Dati con Python e Pandas\n",
    "\n",
    "Benvenuti a questa esercitazione pratica! L'obiettivo di oggi è imparare a esplorare, pulire e visualizzare un dataset reale utilizzando le librerie Python che sono il pane quotidiano di ogni Data Analyst: **Pandas**, **NumPy** e **Matplotlib**.\n",
    "\n",
    "Lavoreremo con il dataset `Dataset Abitudini Sportive`, che raccoglie informazioni sulle abitudini di allenamento di diverse persone. Impareremo a scoprire cosa si nasconde dietro i numeri e a rispondere a domande concrete basate sui dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie che ci servono\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Un piccolo comando per migliorare lo stile dei grafici\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Caricamento del Dataset\n",
    "\n",
    "Per prima cosa, dobbiamo caricare i nostri dati. Assicurati di aver caricato il file `Dataset Abitudini Sportive.csv` nella sessione di Colab (puoi semplicemente trascinarlo nella cartella a sinistra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifichiamo il nome del file\n",
    "file_path = 'Dataset Abitudini Sportive.csv'\n",
    "\n",
    "# Carichiamo il file CSV in un DataFrame di Pandas\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analisi Esplorativa Iniziale\n",
    "\n",
    "Ora che i dati sono caricati, diamo una prima occhiata per capire con cosa abbiamo a che fare. È come aprire il cofano di una macchina per la prima volta: non capiremo subito tutto, ma ci faremo un'idea generale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `df.head()` - Le prime 5 righe\n",
    "Il comando `head()` ci mostra un'anteprima del dataset, utilissima per capire al volo quali sono le colonne e che tipo di dati contengono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `df.info()` - Informazioni sul DataFrame\n",
    "Il metodo `info()` è fondamentale. Ci fornisce una sintesi delle colonne, il numero di valori non nulli e il tipo di dato (Dtype) di ogni colonna. È il nostro primo strumento per scovare eventuali problemi, come dati mancanti o tipi di dato sbagliati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `df.describe()` - Statistiche di base\n",
    "Con `describe()`, otteniamo un riassunto statistico per tutte le colonne numeriche: media, deviazione standard, minimo, massimo e i percentili. Questo ci aiuta a capire la distribuzione dei dati e a identificare possibili valori anomali (outlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pulizia dei Dati (Data Cleaning)\n",
    "\n",
    "Dall'analisi iniziale, abbiamo notato qualcosa di strano. Ad esempio, `df.describe()` mostra un valore minimo di `-999` per alcune colonne, che non ha senso. Inoltre, `df.info()` ci fa capire che alcune colonne numeriche sono state lette come `object` (testo). Questo significa che il nostro dataset è \"sporco\" e ha bisogno di essere pulito.\n",
    "\n",
    "I problemi principali sono:\n",
    "1.  **Valori mancanti codificati come `-999`** in colonne numeriche.\n",
    "2.  **Valori mancanti codificati come `***`** in colonne categoriche (testuali).\n",
    "3.  **Stringhe vuote (`''`)** che impediscono la corretta interpretazione di colonne numeriche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sostituzione dei valori anomali\n",
    "Il primo passo è sostituire tutti i valori usati per indicare dati mancanti (`-999` e `***`) con `np.nan`, un valore speciale di NumPy che Pandas riconosce come \"Not a Number\" (mancante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sostituiamo i valori anomali con NaN\n",
    "df.replace([-999, '***'], np.nan, inplace=True)\n",
    "\n",
    "# Diamo un'occhiata di nuovo alle prime righe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversione dei tipi di dato\n",
    "Ora che abbiamo gestito i valori codificati, dobbiamo correggere i tipi di dato. Forzeremo la conversione delle colonne che dovrebbero essere numeriche al tipo `float`. Useremo `pd.to_numeric` con `errors='coerce'`, un parametro potentissimo che trasformerà automaticamente in `NaN` qualsiasi valore che non riesce a convertire (come le stringhe vuote)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selezioniamo le colonne da convertire\n",
    "colonne_numeriche = ['ore_settimanali_allenamento', 'frequenza_allenamento', 'soddisfazione_allenamento', 'attrezzatura_comprata_annualmente', 'frequenza_infortuni', 'alimentazione_durante_allenamento', 'tempo_riposo_settimanale', 'Y']\n",
    "\n",
    "# Applichiamo la conversione\n",
    "for colonna in colonne_numeriche:\n",
    "    df[colonna] = pd.to_numeric(df[colonna], errors='coerce')\n",
    "\n",
    "# Controlliamo di nuovo i tipi di dato\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifica dei valori mancanti\n",
    "Ora che abbiamo pulito il dataset, usiamo `isnull().sum()` per contare quanti valori mancanti (`NaN`) ci sono in ogni colonna. Questo ci dà la conferma finale del nostro lavoro di pulizia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contiamo i valori NaN per ogni colonna\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizzazione dei Dati\n",
    "\n",
    "I grafici sono il modo migliore per \"vedere\" i dati e scoprire pattern che i numeri da soli non mostrano. Creeremo alcuni grafici di base per esplorare le colonne più interessanti del nostro dataset pulito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Istogramma - Distribuzione delle ore di allenamento\n",
    "Un istogramma è perfetto per visualizzare la distribuzione di una variabile numerica, come le ore di allenamento settimanali. Ci mostra quante persone rientrano in ciascun \"intervallo\" di ore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df['ore_settimanali_allenamento'].hist(bins=15, edgecolor='black')\n",
    "plt.title('Distribuzione delle Ore di Allenamento Settimanali')\n",
    "plt.xlabel('Ore di Allenamento')\n",
    "plt.ylabel('Numero di Persone')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico a Barre - Obiettivi di Allenamento\n",
    "Un grafico a barre è l'ideale per le variabili categoriche. Lo useremo per contare quante persone hanno ciascun obiettivo di allenamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "df['obiettivo_allenamento_label'].value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Frequenza degli Obiettivi di Allenamento')\n",
    "plt.xlabel('Obiettivo')\n",
    "plt.ylabel('Numero di Persone')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout() # Aggiusta il layout per non tagliare le etichette\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico a Barre - Riposo Settimanale\n",
    "Facciamo lo stesso per visualizzare quanto riposano le persone durante la settimana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df['tempo_riposo_settimanale_label'].value_counts().plot(kind='bar', color='lightgreen')\n",
    "plt.title('Frequenza del Riposo Settimanale')\n",
    "plt.xlabel('Giorni di Riposo')\n",
    "plt.ylabel('Numero di Persone')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Formulazione e Verifica di Ipotesi\n",
    "\n",
    "Questa è la parte più divertente: usare i dati per rispondere a delle domande! Formuliamo due semplici ipotesi e vediamo se i dati le confermano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ipotesi 1: Chi punta alla perdita di peso compra meno attrezzatura di chi punta al miglioramento muscolare?\n",
    "\n",
    "**Logica:** Vogliamo confrontare la media di `attrezzatura_comprata_annualmente` per due gruppi specifici. Per farlo, dobbiamo:\n",
    "1.  Filtrare il DataFrame per selezionare solo le righe che ci interessano.\n",
    "2.  Calcolare la media per ciascun gruppo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtriamo i due gruppi\n",
    "gruppo_perdita_peso = df[df['obiettivo_allenamento_label'] == 'Perdita peso']\n",
    "gruppo_massa_muscolare = df[df['obiettivo_allenamento_label'] == 'Miglioramento muscolare']\n",
    "\n",
    "# Calcoliamo la media per ciascun gruppo\n",
    "media_peso = gruppo_perdita_peso['attrezzatura_comprata_annualmente'].mean()\n",
    "media_massa = gruppo_massa_muscolare['attrezzatura_comprata_annualmente'].mean()\n",
    "\n",
    "print(f\"Media spesa per attrezzatura (Perdita peso): {media_peso:.2f} €\")\n",
    "print(f\"Media spesa per attrezzatura (Miglioramento muscolare): {media_massa:.2f} €\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ipotesi 2: C'è una relazione tra la frequenza di allenamento e la soddisfazione?\n",
    "\n",
    "**Logica:** Vogliamo vedere se, in media, le persone che si allenano più spesso sono anche più soddisfatte. Il metodo `groupby()` è perfetto per questo: raggruppa tutte le righe in base a una colonna (la frequenza) e ci permette di calcolare una statistica (la media della soddisfazione) per ogni gruppo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raggruppiamo per frequenza e calcoliamo la soddisfazione media\n",
    "soddisfazione_per_frequenza = df.groupby('frequenza_allenamento')['soddisfazione_allenamento'].mean()\n",
    "\n",
    "print(\"Soddisfazione media per frequenza di allenamento:\")\n",
    "print(soddisfazione_per_frequenza)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}